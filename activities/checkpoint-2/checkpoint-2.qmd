____

This checkpoint question sheet is for you to assess your own progress through Ethics Part 1 and to identify any areas that need further clarifications. It is recommended that you make a written attempt at all questions before solutions are made available to you.

This activity is expected to take approximately **90 minutes** of effort. The available marks for each question are indicated in square brackets, with a total of **26 marks** available.

____

## Confusion at the bank

A bank has developed two new methods of assessing eligibility for a business loan. The head of operations at the bank wishes to compare two new methods to their current approach. They are also concerned about the fairness of the methods, having heard anecdotal evidence that female applicants were being disadvantaged by their current approach.

You have been hired as a consultant to advise on the assessment of the accuracy and fairness of the bank's loan eligibility methods. To assist you, the bank has provided historical loan outcomes from the last year, along with the predictions made by the current and new eligibility methods. These are supplied in `loan_outcomes.csv`. 


a) Construct the confusion matrix for the benchmark method and the two new methods. [3]

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (a)"}
**Solution:**
We can do this by hand or write a function to print the confusion matrices for any such experiment.

```{r print-confusion-matrices-defn}
#| code-fold: true
print_confusion_matrices <- function(df){
  
  # Construct confusion matrix for each test
  CM0 <- data.frame(
    test_pos = c(sum(df$curr_test & df$repaid) , sum(df$curr_test & !df$repaid)),
    test_neg = c(sum(!df$curr_test & df$repaid), sum(!df$curr_test & !df$repaid))
  )

  CM1 <- data.frame(
    test_pos = c(sum(df$new_test_1 & df$repaid) , sum(df$new_test_1 & !df$repaid)),
    test_neg = c(sum(!df$new_test_1 & df$repaid), sum(!df$new_test_1 & !df$repaid))
  )

  CM2 <- data.frame(
    test_pos = c(sum(df$new_test_2 & df$repaid) , sum(df$new_test_2 & !df$repaid)),
    test_neg = c(sum(!df$new_test_2 & df$repaid), sum(!df$new_test_2 & !df$repaid))
  )
  
  # assign meaningful rownames
  rownames(CM0) <- c("repaid", "defaulted")
  rownames(CM1) <- c("repaid", "defaulted")
  rownames(CM2) <- c("repaid", "defaulted")
  
  # Print tables to console
  cat("Current Test \n")
  print(CM0)
  cat("\n")

  cat("New Test 1 \n")
  print(CM1)
  cat("\n")

  cat("New Test 2 \n")
  print(CM2)
  cat("\n")
  
  # Quietly return tables 
  invisible(list(CM0, CM1, CM2))
}
```

Applying this to our dataset, we find: 

```{r print-confusion-matrices}
loan_outcomes <- read.csv("loan_outcomes.csv")
print_confusion_matrices(df = loan_outcomes)
```

**Mark Scheme:**
One mark per correct two-way table. 
:::
::::


b) Calculate the true positive rate and false positive rate for each method. Use these values to recommend which test the bank should use. You should explain the reasoning behind this recommendation. [5] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (b)"}
**Solution:**

Recall the definitions of True Positive Rate and False Positive rate. 

$$\text{TPR} = \frac{TP}{TP + FN} = \frac{\text{\#(Accepted \& Repaid)}}{\text{\#(Repaid)}}$$
$$\text{FPR} = \frac{FP}{FP + TN} = \frac{\text{\#(Accepted \& Defaulted)}}{\text{\#(Defaulted)}}$$

Again, we can write a function to calculate these metrics for any dataset with the given structure. 

```{r print-TPRs-and-FPRs-defn}
#| code-fold: true
print_TPRs_and_FPRs <- function(df){
  # TPR = TP / P = (predicted to repay and did / did repay)
  TPR0 <- sum(df$curr_test & df$repaid)  / sum(df$repaid)
  TPR1 <- sum(df$new_test_1 & df$repaid) / sum(df$repaid)
  TPR2 <- sum(df$new_test_2 & df$repaid) / sum(df$repaid)

  # FPR = FP / N = (predicted to repay and didn't / didn't repay)
  FPR0 <- sum(df$curr_test & !df$repaid) / sum(!df$repaid)
  FPR1 <- sum(df$new_test_1 & !df$repaid) / sum(!df$repaid)
  FPR2 <- sum(df$new_test_2 & !df$repaid) / sum(!df$repaid)

  TPRs <- c(TPR0, TPR1, TPR2)
  FPRs <- c(FPR0, FPR1, FPR2)
  distances <- sqrt((TPRs - 1)^2 + (FPRs - 0)^2)

  out <- data.frame(test = 0:2, TPR = TPRs, FPR = FPRs, distance = distances)
  
  # Print TPR, FPR and interpretation to console
  print(out)
  cat(
    "\n Preferred test is",
    which.min(distances) - 1,
    "(assuming equal treatment of type 1 and 2 errors)."
  )
  
  # Quietly return data frame
  invisible(out)
}
```

And apply this to our particular dataset. 

```{r}
print_TPRs_and_FPRs(df = loan_outcomes)
```

**Mark Scheme:**

- Each pair of correct TPR and FPR (half mark for each). [1] [1] [1] 
- Recommending the test that is closest to (0,1) on a ROC plot (the test with the shorted `distance' value in the R output) [1] 
- Justifying as having the greatest predictive power (or words to that effect) [1] 

_Note: Selecting a different test is okay if justified sufficiently. e.g. bank is risk-adverse and so finds a false-positive defaulting on their loan more damaging than a false-negative where no loan is given._

:::
::::


c) Disaggregate the data by sex and calculate the TPR and FPR of each test by sex. In a few sentences, interpret these results for the head of operations. You should comment on whether the performance of the current test appears to differ by sex. You should also identify the test with the greatest predictive power for males and for non-males.  [5]

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (c)"}

**Solution:** We can now make use of the functions we previously wrote to subset our data by sex and then recalculate the TPRs and FPRs. 

```{r print-TPRs-and-FPRs-by-sex-defn}
#| code-fold: true
print_TPRs_and_FPRs_by_sex <- function(df){

  df_m <- df[df$is_male == 1,]
  df_f <- df[df$is_male == 0,]

  cat('TEST PERFORMANCE ON MALES: \n')
  print_TPRs_and_FPRs(df_m)
  cat("\n ------------------------------------ \n")

  cat('TEST PERFORMANCE ON NON-MALES: \n')
  print_TPRs_and_FPRs(df_f)
  cat("\n ------------------------------------ \n")
}
```

```{r print-TPRs-and-FPRs-by-sex}
print_TPRs_and_FPRs_by_sex(df = loan_outcomes)
```

**Mark Scheme:**

- Sex specific TPRs correct [2]
- Sex specific FPRs correct [2]
- Correct interpretation given in context of loan applications [1]

:::
::::

d) Write a short, contextualised description of error parity, equalised odds and equalised opportunity for the head of operations. [6] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (d)"}
**Solution:** 

**Error parity:** Males and non-males should be mis-classified with the same probability/proportion. Mis-classification occurs here when someone would have repaid a loan they were not given or else failed to repay a loan that they were given. 

**Equalised odds:** The probability of correctly accepting or rejecting the loan application should be the same, regardless of sex. This requires **both** of the following: 

\begin{align*}	
  \Pr(\hbox{ Accepted } | \hbox{ repaid } \& \hbox{ male }) &= \Pr(\hbox{ Accepted } | \hbox{ repaid } \& \hbox{ not male })  \\ 
  \Pr(\hbox{ Rejected } | \hbox{ defaulted } \& \hbox{ male }) &= \Pr(\hbox{ Rejected } | \hbox{ defaulted } \& \hbox{ not male }). 
\end{align*}
     
**Equalised opportunity:** This is a weaker version of equalised odds. The probability of correctly accepting loan application should be the same for those who will repay the loan, regardless of sex. This requires only that: 

$$\Pr(\hbox{ Accepted } | \hbox{ repaid } \& \hbox{ male }) = \Pr(\hbox{ Accepted } | \hbox{ repaid } \& \hbox{ not male })$$

**Mark Scheme:**

Two marks per metric. First mark for correct definition and second mark for each correctly put into context. 

:::
::::

e) Do tests 0, 1 and 2 appear to satisfy error parity by sex? Briefly describe how you might formally assess this. [3]

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (e)"}
**Solution:**

We can again repurprose our existing function to calculate sex-specific error rates. 

```{r print-error-rates-by-sex-defn}
#| code-fold: true
print_error_rates_by_sex <- function(df){
  df_m <- df[df$is_male == 1,]
  df_f <- df[df$is_male == 0,]

  test_0_male_errors <- mean(df_m$curr_test != df_m$repaid)
  test_0_female_errors <- mean(df_f$curr_test != df_f$repaid)

  test_1_male_errors <- mean(df_m$new_test_1 != df_m$repaid)
  test_1_female_errors <- mean(df_f$new_test_1 != df_f$repaid)

  test_2_male_errors <- mean(df_m$new_test_2 != df_m$repaid)
  test_2_female_errors <- mean(df_f$new_test_2 != df_f$repaid)

  test = c(0,1,2)
  male_error_rate <- c(test_0_male_errors, test_1_male_errors, test_2_male_errors)
  female_error_rate <- c(test_0_female_errors, test_1_female_errors, test_2_female_errors)
  relative_error_rate <-  female_error_rate / male_error_rate

  print(data.frame(test, male_error_rate, female_error_rate, relative_error_rate))
}
```

```{r print-error-rates-by-sex}
print_error_rates_by_sex(df = loan_outcomes)
```

- Tests 0 and 1 appear to satisfy error parity since their relative error rate is approximately 1. [1]

- Test 2 has a much higher error rate for people who are not male. [1]

- Formally, we should use a hypothesis test to account for sampling variability in the proportion of misclassified individuals. [1]

:::
::::

f)  Describe the practical and statistical issues in assessing fairness through the use of fairness metrics on this data. [4] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution (f)"}
**Solution:** 

Practically, it is **not possible to satisfy all fairness metrics at once** and so a decision has to be made as to what type of fairness the bank is concerned with. Additionally, some types of fairness **can only be assessed retrospectively**, because they rely on knowing the true outcome of granting the loan. 

Statistically, we want to ensure that the population error rates are equal but must base this on the sample proportions. When samples are small our **power to detect differences may be limited**. If **sampled individuals are not representative of the population** (e.g. only see outcomes for those who were granted loans) then the bias it introduces must be accounted for. 

_Note: Four points given here as examples, only three valid points are required for full marks. These need not be the points listed here but should include at least one practical and one statistical issue._

**Mark Scheme:**

- One valid statistical issue [1] 
- One valid practical issue [1] 
- One additional issue, practical or statistical [1]
- Clear writing and presentation of ideas [1] 

:::
::::

<!-- 
## Toy Shop Anonymity [6]

1. A toy shop is trying to compare spending in two different locations and collects the spending information on its customers.

a. What is the maximum value of $k$ for which the purchase values are $k$-anonymised in Table 1(a)? Give a short justification for your answer. [2]

```{r}
#| echo: false
#| layout-ncol: 3
#| tbl-cap: Toy shop anonymity tables
#| tbl-subcap: true
table_1 <- tibble::tribble(
  ~town,  ~spend,
  "A",     29.99,
  "A",     17.11,
  "A",     33.51,
  "A",     00.10,
  "A",     10.00,
  "A",     07.45,
  "A",     21.99,
  "A",     32.50,
  "A",     20.00,
  "B",     45.99,
  "B",     22.11,
  "B",     04.99,
  "B",     00.25
)

table_2 <- tibble::tribble(
  ~age, ~town, ~spend,
  12,   "A",    29.99,
  11,   "A",    17.11,
  10,   "A",    33.51,
  11,   "A",    00.10,
  12,   "A",    10.00,
  10,   "A",    07.45,
  10,   "A",    21.99,
  12,   "A",    32.50,
  11,   "A",    20.00,
  11,   "B",    45.99,
  11,   "B",    22.11,
  11,   "B",    04.99,
  11,   "B",    00.25
)

table_3 <- tibble::tribble(
~gender, ~age, ~town, ~spend,
 "F",     12,   "A",   29.99,
 "F",     11,   "A",   17.11,
 "F",     10,   "A",   33.51,
 "F",     11,   "A",   00.10,
 "F",     12,   "A",   10.00,
 "M",     10,   "A",   07.45,
 "M",     10,   "A",   21.99,
 "F",     12,   "A",   32.50,
 "F",     11,   "A",   20.00,
 "M",     11,   "B",   45.99,
 "M",     11,   "B",   22.11,
 "F",     11,   "B",   04.99,
 "F",     11,   "B",   00.25
)

knitr::kable(table_1)
knitr::kable(table_2)
knitr::kable(table_3)
```

::::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 1(a)"}
**Note:** For each sub-question, one mark for is for correct answer and one mark is for correct justification.

There are 9 children from town A and only 4 children from town B, therefore Table 1(a) is at most 4-anonymous.
:::
:::::

b) The shop owner wants to account for the age of her customers in her comparison. What is the maximum value of $k$ for which the purchase values are $k$-anonymised in the augmented Table 1(b)? Give a short justification for your answer. [2]

::::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 1(b)"}
The equivalence classes in town A are all the same size $|\{12 \& A\}| = |\{11 \& A\}| = |\{10 \& A\}| = 3$, and there is only a single equivalence class in town B $|\{11 \& B\}| = 4$. The smallest equivalence class is of size 3 and so Table 1(b) is at most 3-anonymous.
:::
:::::

c) She also suspects that there may be a gender gap in pocket money. When gender is included, what is the maximum value of $k$ for which the purchase values are $k$-anonymised in the augmented Table 1(c)? Give a short justification for your answer. [2]

::::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 1(c)"}
Table 1(c) is at most 1-anonymous since the gender-age-town combination for the child represented by the third row is unmatched by any other child in this dataset. 
:::
:::::

## Estimating prevalence of study drug use [16]

A survey is designed to estimate the proportion, $p$, of students engaging in the use of performance enhancing drugs during exam season. To protect individual respondents a randomised response survey design is used, where each student is asked to answer the question "Have you taken performance enhancing drugs during this exam season? (Yes/No)"

A random number generator is used to decide whether each student responds to the question directly or gives a random response. With probability $q$ the student answers directly. If the student answers randomly then they reply "Yes" with probability $q$ and "No" with probability $1-q$.

a) Let $Y$ be the event of responding "Yes", $D$ be the event of having taken performance enhancing drugs and $R$ be the event of responding randomly. Draw a probability tree to describe this randomised response survey. [3]

::::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(a)"}
```{r}
#| echo: false
#| fig-align: center
#| fig-cap: "Probability tree for estimating prevalence of study drug use by a randomised response survey."
#| fig-alt: ""
#| out-width: 80%
knitr::include_graphics("figures/probability_tree_2_a.png")
```

- Correct tree structure (may have Drug use and Random response in either order) [1]
- Correct probabilities [1]
- Presentation and labelling / description of "layers" [1].
:::
:::::

b) What is the probability that a respondent replies "Yes" in this survey? [3]

::::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(b)"}
By the law of total probability:

\begin{align*}
\Pr(Y) =  &\Pr(Y | D \cap R^C) \Pr(D \cap R^C) + \\
          &\Pr(Y | D \cap R) \Pr(D \cap R) +  \\
	        &\Pr(Y | D^C \cap R^C) \Pr(D^C \cap R^C) + \\ 
	        &\Pr(Y | D^C \cap R) \Pr(D^C \cap R).
\end{align*}

Since response randomisation is independent of whether the student has taken drugs we have that 

\begin{align*}
\Pr(Y) =  &\Pr(Y | D \cap R^C) \Pr(D) \Pr(R^C) + \\
          &\Pr(Y | D \cap R) \Pr(D) \Pr(R) +  \\
          &\Pr(Y | D^C \cap R^C) \Pr(D^C) \Pr(R^C) + \\
          &\Pr(Y | D^C \cap R) \Pr(D^C) \Pr(R).
\end{align*}

Substituting the given probabilities:

\begin{align*}
\Pr(Y) &= 1pq + q p (1 - q) + 0(1-p)q + q(1-p)(1-q) \\
       &= pq + p(1-q)q + (1-p)(1-q)q \\
       & = q( p + 1 - q ).
\end{align*}

- correct answer [1]
- correct working [1]
- description / justification of steps [1].
:::
::::

c) Janine replied "Yes" in the survey. What is the probability that she had not taken performance enhancing drugs? [2] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(c)"}
Applying Bayes' rule and the law of total probability we may find the probability of not taking drugs, given a response of "Yes":

\begin{align*}
    \Pr(D^C | Y) &= \frac{\Pr(D^C \cap Y)}{\Pr(Y)} \\[1.5em]
                 &= \frac{(1-p)(1-q)q}{pq + p(1-q)q + (1-p)(1-q)q} \\[1.5em]
                 &= \frac{(1-p)(1-q)}{p + p(1-q) + (1-p)(1-q)} \\[1.5em]
                 &= \frac{(1-p)(1-q)}{p + 1 - q}.
\end{align*}

- Working [1]
- Answer [1]
:::
::::

d) By equating the sample and population proportions of respondents answering "Yes:, derive the method of moments estimator $\hat P$ for $p$ based on $n$ responses to this survey design. In your derivation, denote the survey responses $Y_1, Y_2, \ldots, Y_n$ where $Y_i = 1$ if the student answered "Yes" and $Y_i = 0$ if the student answered "No". Let the mean of these responses be $\bar Y$. [2]

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(d)"}
We previously showed that $\Pr(Y) = q (p + 1 - q)$. Rearranging this expression for $p$ we find that: 

$$ p = \frac{\Pr(Y)}{q} - 1 + q.$$ 

Replacing $\Pr(Y)$ by its method of moments estimator $\bar Y$, we obtain a method of moments estimator for $p$:

$$ \hat P = \frac{\bar Y}{q} - 1 + q.$$

- Correct and justified working [1]
- Correct answer [1] 

:::
::::

e) Explain why values of  0 and 1 for $q$ would not be suitable in this survey design. [2] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(e)"}
Firstly, setting $q = 1$ would not be suitable because then all students would answer honestly, defeating the aim of providing responding students with plausible deniability. [1] (1 mark for valid reasoning)

Secondly, setting $q = 0$ would cause at least two issues:  the first of these is that all students would respond randomly (which is actually a deterministic "No", since $q=0$) and we would gain no useful information about the proportion of students taking study drugs. Secondly, the estimator $\hat P$ is not well defined when $q = 0$. [1] (1 mark for one or more valid reasons)
:::
::::

f)  For which values of $q$ does the method of moments estimate $\hat p$ yield a valid probability? Why is it challenging to select $q$ to satisfy this condition? [2] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(f)"}
To ensure the estimate $\hat p$ is a valid probability it must be in the range [0,1]. To ensure that this is the case we must select $q$ such that $0 \leq \frac{\bar y}{q} - 1 + q \leq 1$.

Enforcing this constraint is non-trivial because the value for $q$ is selected before the survey is taken, and so $\hat y$ is unknown.  (This is further complicated by the fact that the distribution of $\hat Y$ depends  on both the unknown, true proportion $p$ and the value that will be chosen for $q$.)

(1 mark for condition, 1 mark for valid reasoning)

:::
::::

g) Of the 150 students surveyed using the randomised response survey design using $q = 0.4$, 99 students responded "No". Calculate a point estimate for the proportion of students who have taken performance enhancing drugs this exam season. [2]


:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(g)"}

Using this survey data $\hat{\text{Pr}}(Y) = 1 - \frac{99}{150} = \frac{51}{50}$ and



$$\hat p = \frac{51}{150 \times \frac{4}{10}} - 1 + \frac{4}{10} = \frac{51}{60} - \frac{36}{60} = \frac{1}{4} .$$

Therefore, based on this survey, our best estimate for the proportion of students using performance enhancing drugs is $25\%$. 

- Correct working and justification [1]
- Correct answer, given in context [1]

:::
::::


## Ethical AI in Social Media [10]

A social media company collects information about its users and their browsing history. The company use this information to construct and deploy an automated system that suggests future content and advertisements to each user based on their characteristics and previous activity.  

In this context, briefly explain each of the five principles of ethical AI as given in "A unified framework of five principles for AI in society" (Floridi and Cowls 2019)  and give an example of what each could mean in practical terms. [10] 

:::: {.content-visible when-profile="solutions"}
::: {.callout-tip title="Solution 2(g)"}

1. **Beneficence:** Promoting Well-Being, Preserving Dignity, and Sustaining the Planet. 
  - *Principle:* The use of the recommender system should benefit the user, society or the environment in some way.
  - *Example context:* Recommended content might be more relevant to that user than generic recommendations, the system may also raise awareness of, for example,  social or environmental issues.
  
2. **Non-maleficence:** Privacy, Security and ‘Capability Caution’.
  - *Principle:* The use of the recommender system should not cause harm to individual users, society or the environment.
  - *Example context:* The recommender system should not produce echo-chambers, where users are not exposed to opinions and beliefs that contradict their own, thereby leading to a more polarised society.

3. **Autonomy:** The Power to Decide (to Decide).
  - *Principle:* The use of the recommender system should not impair the freedom of human beings to set their own standards and norms.
  - *Example context:* Humans, whether staff members of the social media company or users, should be able to intervene and over-ride the recommendations made by e.g. turning off all tailored content or `muting' topics such as maternity content.

4. **Justice:** Promoting Prosperity, Preserving Solidarity, Avoiding Unfairness. 
  - *Principle:* The use of the recommender system should seek to eliminate existing injustice and discrimination and to provide equitable access to the benefits of the system.
  - *Example context:* The recommendations made should be equitable across all members of society, this could fail if skin-tone biases or Eurocentric beauty standards are exacerbated by the recommendations made by the system.

5. **Explicability:** Explaining how a model works and individual predictions.
  - *Principle:* Users who are not experts in recommender systems should be able to understand why they are being shown certain content.
  - *Example context:* Personalised content might be displayed with a message such as `users who follow X also follow Y', or 'because you liked Z ...'.

:::
::::

-->
